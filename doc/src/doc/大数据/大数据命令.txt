在cd /usr/local/src/kafka_2.10-0.10.0.0目录下
 nohup /usr/local/src/kafka_2.10-0.10.0.0/bin/kafka-server-start.sh /usr/local/src/kafka_2.10-0.10.0.0/config/server.properties &
创建主题/usr/local/src/kafka_2.10-0.10.0.0/bin/kafka-topics.sh --zookeeper 192.168.181.130:2191,192.168.181.134:2192,192.168.181.135:2193 --topic cache-message --replication-factor 1 --partitions 1 --create
创建生产者bin/kafka-console-producer.sh --broker-list 192.168.181.130:9092,192.168.181.134:9092,192.168.181.135:9092 --topic cache-message
创建消费者bin/kafka-console-consumer.sh --zookeeper 192.168.181.130:2191,192.168.181.134:2192,192.168.181.135:2193 --topic test --from-beginning

shell脚本  授权chmod +x ./test.sh

/usr/local/src/spark/bin/spark-submit  --master yarn --executor-memory 4g --jars /usr/local/src/hive/lib/mysql-connector-java-5.1.35-bin.jar --class www.dajiangtai.com.datacleaner.ETL  /usr/local/src/spark.jar
/usr/local/src/spark/bin/spark-submit  --master spark://storage9:7077  --jars /usr/local/src/hive/lib/mysql-connector-java-5.1.35-bin.jar --class www.dajiangtai.com.datacleaner.ETL  /usr/local/src/spark.jar

/usr/local/src/spark/bin/spark-submit  --master yarn --executor-memory 4g  --jars /usr/local/src/hive/lib/mysql-connector-java-5.1.35-bin.jar --class www.dajiangtai.com.datacleaner.RatingData  /usr/local/src/spark.jar 
 /usr/local/src/spark/bin/spark-submit  --master spark://storage9:7077 --executor-memory 4g  --jars /usr/local/src/hive/lib/mysql-connector-java-5.1.35-bin.jar --class www.dajiangtai.com.datacleaner.RatingData  /usr/local/src/spark.jar 

 /usr/local/src/spark/bin/spark-submit  --master yarn --executor-memory 4g  --jars /usr/local/src/hive/lib/mysql-connector-java-5.1.35-bin.jar --class www.dajiangtai.com.ml.ModelTraining  /usr/local/src/spark.jar 
 /usr/local/src/spark/bin/spark-submit  --master spark://storage9:7077 --executor-memory 4g  --jars /usr/local/src/hive/lib/mysql-connector-java-5.1.35-bin.jar --class www.dajiangtai.com.ml.ModelTraining  /usr/local/src/spark.jar 

  /usr/local/src/spark/bin/spark-submit  --master spark://storage9:7077 --executor-memory 2g  --jars /usr/local/src/hive/lib/mysql-connector-java-5.1.35-bin.jar --class www.dajiangtai.com.ml.RecommendForAllUsers  /usr/local/src/spark.jar 
 
 /usr/local/src/spark/bin/spark-submit --master spark://storage9:7077 --executor-memory 2g --jars /usr/local/src/hive/lib/mysql-connector-java-5.1.35-bin.jar,/usr/local/src/spark/lib/kafka-clients-0.10.0.0.jar,/usr/local/src/spark/lib/metrics-core-3.1.2.jar,/usr/local/src/spark/lib/spark-streaming-kafka_2.10-1.6.2.jar,/usr/local/src/spark/lib/kafka_2.10-0.10.0.0.jar --class www.dajiangtai.com.streaming.SparkDirectStream /usr/local/src/spark.jar
  /usr/local/src/spark/bin/spark-submit --master spark://storage9:7077 --executor-memory 2g  --class www.dajiangtai.com.streaming.SparkDirectStream /usr/local/src/spark.jar
 启动hive远程

bin/hive --service hiveserver2 

hdfs://ns1/user/hive/warehouse


第一步：在pom.xml文件中添加，其中标红的部分，我在实际应用中是去掉的，因为我这个jar单纯是工具类，没有主函数，如果有的话，红色部分改成自己的启动类应该就行了
第二步：右键pom.xml--->run config里运行命令输入assembly:assembly
 
  --master yarn
 --master yarn-cluster


sqlContext.setConf("spark.sql.shuffle.partitions", "40") 默认200
sqlContext.setConf("spark.sql.autoBroadcastJoinThreshold", "100")   默认10m（10485760）
spark.network.timeout 
优化

1.内存

当然如果你的任务shuffle量特别大，同时rdd缓存比较少可以更改下面的参数进一步提高任务运行速度。

spark.storage.memoryFraction - 分配给rdd缓存的比例，默认为0.6(60%)，如果缓存的数据较少可以降低该值。

spark.shuffle.memoryFraction - 分配给shuffle数据的内存比例，默认为0.2(20%)

剩下的20%内存空间则是分配给代码生成对象等。

如果任务运行缓慢，jvm进行频繁gc或者内存空间不足，或者可以降低上述的两个值。

"spark.rdd.compress","true" - 默认为false，压缩序列化的RDD分区,消耗一些cpu减少空间的使用

如果数据只使用一次，不要采用cache操作，因为并不会提高运行速度，还会造成内存浪费。

2.并行度

spark.default.parallelism 
发生shuffle时的并行度，在standalone模式下的数量默认为core的个数，也可手动调整，数量设置太大会造成很多小任务，增加启动任务的开销，太小，运行大数据量的任务时速度缓慢。

spark.sql.shuffle.partitions 
sql聚合操作(发生shuffle)时的并行度，默认为200,如果任务运行缓慢增加这个值。

6台服务器 1000qps 2千万

1G 4000万数据   etl 3分钟  切分训练集5分钟  训练3分钟


4g  2千万    96G 8核（8台16g8核）





${SPARK_HOME}/bin/spark-submit \
--master=spark://storage9:7077 \
--conf spark.executorEnv.LD_LIBRARY_PATH="${JAVA_HOME}/jre/lib/amd64/server" \
--conf spark.executorEnv.CLASSPATH="$($HADOOP_HOME/bin/hadoop classpath --glob):${CLASSPATH}" \
--py-files ${TFoS_HOME}/examples/mnist/spark/mnist_dist.py,${TFoS_HOME}/tfspark.zip \
--conf spark.cores.max=8 \
--conf spark.task.cpus=4 \
${TFoS_HOME}/examples/mnist/spark/mnist_spark.py \
--cluster_size 2 \
--images examples/mnist/csv/train/images \
--labels examples/mnist/csv/train/labels \
--format csv \
--mode train \
--model mnist_model


${SPARK_HOME}/bin/spark-submit \
--master spark://storage9:7077 \
--conf spark.executorEnv.LD_LIBRARY_PATH="${JAVA_HOME}/jre/lib/amd64/server" \
--conf spark.executorEnv.CLASSPATH="$($HADOOP_HOME/bin/hadoop classpath --glob):${CLASSPATH}" \
--py-files ${TFoS_HOME}/tfspark.zip,${TFoS_HOME}/examples/mnist/spark/mnist_dist.py \
--conf spark.cores.max=8 \
--conf spark.task.cpus=4 \
--conf spark.executorEnv.JAVA_HOME="$JAVA_HOME" \
${TFoS_HOME}/examples/mnist/spark/mnist_spark.py \
--cluster_size 2 \
--images examples/mnist/csv/test/images \
--labels examples/mnist/csv/test/labels \
--mode inference \
--format csv \
--model mnist_model \
--output predictions